{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95651b1e-0644-4884-ad61-0f7efac7393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sulaimon/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from os import path\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import wget\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
    "import csv\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "\n",
    "import lpips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc324d-3da2-4be6-9ce5-16f10147ddda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6610a48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14999 Images.\n"
     ]
    }
   ],
   "source": [
    "##Check if data path is correct\n",
    "data_path = \"/home/sulaimon/EXPERIMENT/23/images_001\"\n",
    "image_files = glob.glob(os.path.join(data_path, '*.png'))\n",
    "print(f'Found {len(image_files)} Images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f16dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee04374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (14999, 1, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "#=====Load Data=====\n",
    "def load_xray_image(data_path):\n",
    "    img = Image.open(data_path).convert('L')  # Ensure grayscale\n",
    "    img = img.resize((256, 256))              # Resize to 256x256\n",
    "    img_array = np.array(img, dtype=np.float32) / 255.0  # Normalize to [0,1]\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add channel dimension: (1, 256, 256)\n",
    "    return img_array\n",
    "\n",
    "# Load all images into a numpy array\n",
    "InputImages = np.array([load_xray_image(f) for f in image_files])\n",
    "print(\"Dataset Shape:\", InputImages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78586946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a40b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Add Noise=====\n",
    "def add_gaussian_noise(images, mean=0.1, stddev=0.1):\n",
    "    noise = torch.normal( mean, std=stddev, size=images.shape)\n",
    "    noisy_images = images + noise\n",
    "    return torch.clamp(noisy_images, 0., 1.)\n",
    "\n",
    "InputImages = torch.tensor(InputImages, dtype=torch.float32)\n",
    "noisy_images = add_gaussian_noise(InputImages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e0c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0b23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Noisy shape: torch.Size([32, 1, 256, 256]), Clean shape: torch.Size([32, 1, 256, 256])\n",
      "Validation set: Noisy shape: torch.Size([32, 1, 256, 256]), Clean shape: torch.Size([32, 1, 256, 256])\n",
      "Test set: Noisy shape: torch.Size([32, 1, 256, 256]), Clean shape: torch.Size([32, 1, 256, 256])\n",
      "Train set size: 7499\n",
      "Val Set: 4949\n",
      "Test Set: 2551\n"
     ]
    }
   ],
   "source": [
    "#=====Data Loader=====\n",
    "class X_rayDataset(Dataset):\n",
    "    def __init__(self, noisy, clean):\n",
    "        self.noisy = noisy\n",
    "        self.clean = clean\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.noisy)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.noisy[idx], self.clean[idx]\n",
    "\n",
    "\n",
    "##Splitting and Data Loader Creation\n",
    "dataset = X_rayDataset(noisy_images, InputImages)\n",
    "\n",
    "#Ensuring reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "train_size = int(0.5 * len(dataset))\n",
    "val_size = int(0.33 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False)\n",
    "\n",
    "##Verify the samples\n",
    "def print_dataset_shapes(loader, name):\n",
    "    data_iter = iter(loader)\n",
    "    noisy_sample, clean_sample = next(data_iter)\n",
    "    print(f\"{name} set: Noisy shape: {noisy_sample.shape}, Clean shape: {clean_sample.shape}\")\n",
    "\n",
    "print_dataset_shapes(train_loader, \"Train\")\n",
    "print_dataset_shapes(val_loader, \"Validation\")\n",
    "print_dataset_shapes(test_loader, \"Test\")\n",
    "\n",
    "print(f\"Train set size: {len(train_set)}\")\n",
    "print(f\"Val Set: {len(val_set)}\")\n",
    "print(f\"Test Set: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb88f69-0d3b-4702-9b26-d5721ceb34c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9564a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs with DataParallel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): UNet(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv4): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "    )\n",
       "    (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv5): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "    )\n",
       "    (upconv6): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv6): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "    )\n",
       "    (upconv7): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv7): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "    )\n",
       "    (upconv8): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv8): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "    )\n",
       "    (upconv9): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    (conv9): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "    )\n",
       "    (final_conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#=====UNet Model Definition=====\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_channels=1, Nc=64):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Contracting Path\n",
    "        self.conv1 = self.conv_block(input_channels, Nc)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv2 = self.conv_block(Nc, Nc * 2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv3 = self.conv_block(Nc * 2, Nc * 4)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv4 = self.conv_block(Nc * 4, Nc * 8)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv5 = self.conv_block(Nc * 8, Nc * 16)\n",
    "\n",
    "        # Expanding Path\n",
    "        self.upconv6 = nn.ConvTranspose2d(Nc * 16, Nc * 8, kernel_size=2, stride=2)\n",
    "        self.conv6 = self.conv_block(Nc * 16, Nc * 8)\n",
    "\n",
    "        self.upconv7 = nn.ConvTranspose2d(Nc * 8, Nc * 4, kernel_size=2, stride=2)\n",
    "        self.conv7 = self.conv_block(Nc * 8, Nc * 4)\n",
    "\n",
    "        self.upconv8 = nn.ConvTranspose2d(Nc * 4, Nc * 2, kernel_size=2, stride=2)\n",
    "        self.conv8 = self.conv_block(Nc * 4, Nc * 2)\n",
    "\n",
    "        self.upconv9 = nn.ConvTranspose2d(Nc * 2, Nc, kernel_size=2, stride=2)\n",
    "        self.conv9 = self.conv_block(Nc * 2, Nc)\n",
    "\n",
    "        # Final output for grayscale (only 1 channel)\n",
    "        self.final_conv = nn.Conv2d(Nc, 1, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = {}\n",
    "\n",
    "        # Contracting Path\n",
    "        outputs[\"conv1\"] = self.conv1(x)\n",
    "        pool1 = self.pool1(outputs[\"conv1\"])\n",
    "\n",
    "        outputs[\"conv2\"] = self.conv2(pool1)\n",
    "        pool2 = self.pool2(outputs[\"conv2\"])\n",
    "\n",
    "        outputs[\"conv3\"] = self.conv3(pool2)\n",
    "        pool3 = self.pool3(outputs[\"conv3\"])\n",
    "\n",
    "        outputs[\"conv4\"] = self.conv4(pool3)\n",
    "        pool4 = self.pool4(outputs[\"conv4\"])\n",
    "\n",
    "        outputs[\"conv5\"] = self.conv5(pool4)  # Bottleneck\n",
    "\n",
    "        # Expanding Path\n",
    "        up6 = self.upconv6(outputs[\"conv5\"])\n",
    "        merge6 = torch.cat((outputs[\"conv4\"], up6), dim=1)\n",
    "        outputs[\"conv6\"] = self.conv6(merge6)\n",
    "\n",
    "        up7 = self.upconv7(outputs[\"conv6\"])\n",
    "        merge7 = torch.cat((outputs[\"conv3\"], up7), dim=1)\n",
    "        outputs[\"conv7\"] = self.conv7(merge7)\n",
    "\n",
    "        up8 = self.upconv8(outputs[\"conv7\"])\n",
    "        merge8 = torch.cat((outputs[\"conv2\"], up8), dim=1)\n",
    "        outputs[\"conv8\"] = self.conv8(merge8)\n",
    "\n",
    "        up9 = self.upconv9(outputs[\"conv8\"])\n",
    "        merge9 = torch.cat((outputs[\"conv1\"], up9), dim=1)\n",
    "        outputs[\"conv9\"] = self.conv9(merge9)\n",
    "\n",
    "        outputs[\"final\"] = self.final_conv(outputs[\"conv9\"])\n",
    "\n",
    "        return outputs  # Return all intermediate outputs\n",
    "\n",
    "# Example usage with DataParallel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(input_channels=1, Nc=64)\n",
    "\n",
    "# Wrap with DataParallel if more than one GPU\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs with DataParallel\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a1a25c-c571-40ca-b861-78bb74de9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Metrics=====\n",
    "def psnr_metric(y_true, y_pred):\n",
    "    mse = F.mse_loss(y_pred, y_true)\n",
    "    return 10 * torch.log10(1.0 / mse)\n",
    "\n",
    "def ssim_metric(y_true, y_pred):\n",
    "    y_true = y_true.detach().cpu().numpy()\n",
    "    y_pred = y_pred.detach().cpu().numpy()\n",
    "    ssim_scores = []\n",
    "    for i in range(y_true.shape[0]):  # loop over batch\n",
    "        ssim_score = ssim(y_true[i,0], y_pred[i,0], data_range=1.0)  # Only first (and only) channel\n",
    "        ssim_scores.append(ssim_score)\n",
    "    return torch.tensor(ssim_scores).mean()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.L1Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a372096-52e8-46fd-83c9-6159607e9b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d7b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/50 => Train Loss: 0.044421, Validation Loss: 0.047310\n",
      "Model saved at epoch 1 with best validation loss: 0.047310\n",
      "Epoch 2/50 => Train Loss: 0.031486, Validation Loss: 0.025958\n",
      "Model saved at epoch 2 with best validation loss: 0.025958\n",
      "Epoch 3/50 => Train Loss: 0.028396, Validation Loss: 0.042595\n",
      "Epoch 4/50 => Train Loss: 0.026298, Validation Loss: 0.030584\n",
      "Epoch 5/50 => Train Loss: 0.025326, Validation Loss: 0.025915\n",
      "Model saved at epoch 5 with best validation loss: 0.025915\n",
      "Epoch 6/50 => Train Loss: 0.024750, Validation Loss: 0.039112\n",
      "Epoch 7/50 => Train Loss: 0.022577, Validation Loss: 0.023523\n",
      "Model saved at epoch 7 with best validation loss: 0.023523\n",
      "Epoch 8/50 => Train Loss: 0.023542, Validation Loss: 0.035316\n",
      "Epoch 9/50 => Train Loss: 0.021107, Validation Loss: 0.026951\n",
      "Epoch 10/50 => Train Loss: 0.022833, Validation Loss: 0.020273\n",
      "Model saved at epoch 10 with best validation loss: 0.020273\n",
      "Epoch 11/50 => Train Loss: 0.021419, Validation Loss: 0.021530\n",
      "Epoch 12/50 => Train Loss: 0.021012, Validation Loss: 0.026347\n",
      "Epoch 13/50 => Train Loss: 0.020569, Validation Loss: 0.023867\n",
      "Epoch 14/50 => Train Loss: 0.020206, Validation Loss: 0.016884\n",
      "Model saved at epoch 14 with best validation loss: 0.016884\n",
      "Epoch 15/50 => Train Loss: 0.019152, Validation Loss: 0.019738\n",
      "Epoch 16/50 => Train Loss: 0.020126, Validation Loss: 0.019811\n",
      "Epoch 17/50 => Train Loss: 0.019530, Validation Loss: 0.020662\n",
      "Epoch 18/50 => Train Loss: 0.018891, Validation Loss: 0.017565\n",
      "Epoch 19/50 => Train Loss: 0.018950, Validation Loss: 0.020307\n",
      "Epoch 20/50 => Train Loss: 0.018887, Validation Loss: 0.020066\n",
      "Epoch 21/50 => Train Loss: 0.018353, Validation Loss: 0.023619\n",
      "Epoch 22/50 => Train Loss: 0.018828, Validation Loss: 0.020564\n",
      "Epoch 23/50 => Train Loss: 0.017922, Validation Loss: 0.030114\n",
      "Epoch 24/50 => Train Loss: 0.018276, Validation Loss: 0.020823\n",
      "Epoch 25/50 => Train Loss: 0.018034, Validation Loss: 0.016653\n",
      "Model saved at epoch 25 with best validation loss: 0.016653\n",
      "Epoch 26/50 => Train Loss: 0.017480, Validation Loss: 0.017404\n",
      "Epoch 27/50 => Train Loss: 0.017262, Validation Loss: 0.018462\n",
      "Epoch 28/50 => Train Loss: 0.017516, Validation Loss: 0.017953\n",
      "Epoch 29/50 => Train Loss: 0.017825, Validation Loss: 0.018089\n",
      "Epoch 30/50 => Train Loss: 0.017776, Validation Loss: 0.021200\n",
      "Epoch 31/50 => Train Loss: 0.017010, Validation Loss: 0.016025\n",
      "Model saved at epoch 31 with best validation loss: 0.016025\n",
      "Epoch 32/50 => Train Loss: 0.016821, Validation Loss: 0.017728\n",
      "Epoch 33/50 => Train Loss: 0.016636, Validation Loss: 0.015594\n",
      "Model saved at epoch 33 with best validation loss: 0.015594\n",
      "Epoch 34/50 => Train Loss: 0.016953, Validation Loss: 0.017081\n",
      "Epoch 35/50 => Train Loss: 0.016398, Validation Loss: 0.016043\n",
      "Epoch 36/50 => Train Loss: 0.016659, Validation Loss: 0.045218\n",
      "Epoch 37/50 => Train Loss: 0.016337, Validation Loss: 0.018651\n",
      "Epoch 38/50 => Train Loss: 0.016016, Validation Loss: 0.016248\n",
      "Epoch 39/50 => Train Loss: 0.016528, Validation Loss: 0.015755\n",
      "Epoch 40/50 => Train Loss: 0.015857, Validation Loss: 0.015013\n",
      "Model saved at epoch 40 with best validation loss: 0.015013\n",
      "Epoch 41/50 => Train Loss: 0.015729, Validation Loss: 0.014415\n",
      "Model saved at epoch 41 with best validation loss: 0.014415\n",
      "Epoch 42/50 => Train Loss: 0.015641, Validation Loss: 0.015687\n",
      "Epoch 43/50 => Train Loss: 0.015342, Validation Loss: 0.014975\n",
      "Epoch 44/50 => Train Loss: 0.015431, Validation Loss: 0.014495\n",
      "Epoch 45/50 => Train Loss: 0.014950, Validation Loss: 0.014261\n",
      "Model saved at epoch 45 with best validation loss: 0.014261\n",
      "Epoch 46/50 => Train Loss: 0.014910, Validation Loss: 0.016647\n",
      "Epoch 47/50 => Train Loss: 0.014844, Validation Loss: 0.015804\n",
      "Epoch 48/50 => Train Loss: 0.014684, Validation Loss: 0.016483\n",
      "Epoch 49/50 => Train Loss: 0.014692, Validation Loss: 0.015062\n",
      "Epoch 50/50 => Train Loss: 0.014232, Validation Loss: 0.015887\n"
     ]
    }
   ],
   "source": [
    "#=====Training=====\n",
    "def train_model(model, train_loader, val_loader, epochs=50, save_path=\"best_model_unet_DP_10.pth\"):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model.to(device)  # Move model to GPU if available\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.L1Loss()  # Use L1Loss as defined earlier\n",
    "\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for noisy, clean in train_loader:\n",
    "            noisy, clean = noisy.to(device), clean.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(noisy)[\"final\"]\n",
    "            loss = loss_fn(outputs, clean)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for noisy, clean in val_loader:\n",
    "                noisy, clean = noisy.to(device), clean.to(device)\n",
    "\n",
    "                outputs = model(noisy)[\"final\"]\n",
    "                loss = loss_fn(outputs, clean)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} => Train Loss: {avg_train_loss:.6f}, Validation Loss: {avg_val_loss:.6f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Model saved at epoch {epoch+1} with best validation loss: {best_loss:.6f}\")\n",
    "\n",
    "# Example: Call training\n",
    "train_model(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b9bfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbed35e6-f155-49fc-ba18-9049033bbed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e2bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Initialize LPIPS model globally )\n",
    "loss_fn_lpips = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "#=====Model Testing=====\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    total_psnr = 0.0\n",
    "    total_ssim = 0.0\n",
    "    total_lpips = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for noisy, clean in test_loader:\n",
    "            noisy, clean = noisy.to(device), clean.to(device)\n",
    "            outputs = model(noisy)[\"final\"]\n",
    "\n",
    "            for i in range(noisy.shape[0]):\n",
    "                y_true = clean[i,0].cpu().numpy()   # (H,W) for grayscale\n",
    "                y_pred = outputs[i,0].cpu().numpy() # (H,W) for grayscale\n",
    "\n",
    "                total_psnr += psnr(y_true, y_pred, data_range=1.0)\n",
    "                total_ssim += ssim(y_true, y_pred, data_range=1.0, win_size=3)  # multichannel=False by default\n",
    "\n",
    "                # LPIPS: convert single-channel to 3-channel and normalize to [-1, 1]\n",
    "                out_img = outputs[i].unsqueeze(0)  # [1, 1, H, W]\n",
    "                tgt_img = clean[i].unsqueeze(0)    # [1, 1, H, W]\n",
    "\n",
    "                if out_img.shape[1] == 1:\n",
    "                    out_img = out_img.repeat(1, 3, 1, 1)\n",
    "                    tgt_img = tgt_img.repeat(1, 3, 1, 1)\n",
    "\n",
    "                out_img = (out_img * 2) - 1\n",
    "                tgt_img = (tgt_img * 2) - 1\n",
    "\n",
    "                lpips_score = loss_fn_lpips(out_img.to(device), tgt_img.to(device))\n",
    "                total_lpips += lpips_score.item()\n",
    "\n",
    "                num_samples += 1\n",
    "\n",
    "    avg_psnr = total_psnr / num_samples\n",
    "    avg_ssim = total_ssim / num_samples\n",
    "    avg_lpips = total_lpips / num_samples\n",
    "\n",
    "    print(f\"Average PSNR: {avg_psnr:.2f} dB\")\n",
    "    print(f\"Average SSIM: {avg_ssim:.4f}\")\n",
    "    print(f\"Average LPIPS: {avg_lpips:.4f}\")\n",
    "    print(f\"Test samples evaluated: {num_samples}\")\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_unet_DP_10.pth', map_location=device))\n",
    "\n",
    "test_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171b6f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Save Sample Test Data=====\n",
    "def save_test_image_triplets_from_model(model, test_loader, device=\"cpu\", output_dir=\"saved_unet_imagesDT\"):\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get one batch from the test set\n",
    "    noisy_imgs, clean_imgs = next(iter(test_loader))\n",
    "    noisy_imgs = noisy_imgs.to(device)\n",
    "    clean_imgs = clean_imgs.to(device)\n",
    "\n",
    "    # Run inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_imgs = model(noisy_imgs)[\"final\"]  # Assuming model returns dict with key \"final\"\n",
    "\n",
    "    # Move to CPU for saving\n",
    "    noisy_imgs = noisy_imgs.cpu()\n",
    "    output_imgs = output_imgs.cpu()\n",
    "    clean_imgs = clean_imgs.cpu()\n",
    "\n",
    "    # Save the first 10 triplets\n",
    "    for i in range(min(10, len(clean_imgs))):\n",
    "        save_image(noisy_imgs[i], os.path.join(output_dir, f\"img_{i+1:02d}_noisy.png\"))\n",
    "        save_image(output_imgs[i], os.path.join(output_dir, f\"img_{i+1:02d}_denoised.png\"))\n",
    "        save_image(clean_imgs[i], os.path.join(output_dir, f\"img_{i+1:02d}_clean.png\"))\n",
    "\n",
    "    print(f\"Saved {min(10, len(clean_imgs)) * 3} images (triplets) to '{output_dir}'\")\n",
    "\n",
    "save_test_image_triplets_from_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe50a07e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ec5379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/sulaimon/.local/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      " Saved PSNR/SSIM/LPIPS metrics for 2551 images to 'unet_DP_10.csv'\n"
     ]
    }
   ],
   "source": [
    "#=====Save Metrics to CSV=====\n",
    "def save_metrics_csv_from_model(model, test_loader, device=\"cpu\", csv_path=\"unet_DP_10.csv\"):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn_lpips = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "    psnr_list = []\n",
    "    ssim_list = []\n",
    "    lpips_list = []\n",
    "    count = 0\n",
    "\n",
    "    with open(csv_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Image Index\", \"PSNR\", \"SSIM\", \"LPIPS\"])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for noisy, clean in test_loader:\n",
    "                noisy = noisy.to(device)\n",
    "                clean = clean.to(device)\n",
    "\n",
    "                outputs = model(noisy)[\"final\"]\n",
    "\n",
    "                clean_np = clean.squeeze(1).cpu().numpy()     # (B, H, W)\n",
    "                outputs_np = outputs.squeeze(1).cpu().numpy() # (B, H, W)\n",
    "\n",
    "                for i in range(clean_np.shape[0]):\n",
    "                    # PSNR & SSIM\n",
    "                    psnr_val = psnr(clean_np[i], outputs_np[i], data_range=1.0)\n",
    "                    ssim_val = ssim(clean_np[i], outputs_np[i], data_range=1.0, win_size=3)\n",
    "\n",
    "                    # LPIPS: prepare 3-channel normalized input\n",
    "                    out_img = outputs[i].unsqueeze(0)  # [1, 1, H, W]\n",
    "                    tgt_img = clean[i].unsqueeze(0)\n",
    "\n",
    "                    if out_img.shape[1] == 1:\n",
    "                        out_img = out_img.repeat(1, 3, 1, 1)\n",
    "                        tgt_img = tgt_img.repeat(1, 3, 1, 1)\n",
    "\n",
    "                    out_img = (out_img * 2) - 1\n",
    "                    tgt_img = (tgt_img * 2) - 1\n",
    "\n",
    "                    lpips_val = loss_fn_lpips(out_img.to(device), tgt_img.to(device)).item()\n",
    "\n",
    "                    psnr_list.append(psnr_val)\n",
    "                    ssim_list.append(ssim_val)\n",
    "                    lpips_list.append(lpips_val)\n",
    "\n",
    "                    writer.writerow([count + 1, psnr_val, ssim_val, lpips_val])\n",
    "                    count += 1\n",
    "\n",
    "        writer.writerow([])  # Blank line\n",
    "        writer.writerow([\"Average\", np.mean(psnr_list), np.mean(ssim_list), np.mean(lpips_list)])\n",
    "\n",
    "    print(f\" Saved PSNR/SSIM/LPIPS metrics for {count} images to '{csv_path}'\")\n",
    "    \n",
    "save_metrics_csv_from_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038df01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772129f3-c8ea-403f-a624-10b38b013b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Visualise Clean, Noisy, and Denoised Image Test sets=====\n",
    "def visualize_results(model, test_loader, device, num_samples=10):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    data_iter = iter(test_loader)\n",
    "    noisy, clean = next(data_iter)\n",
    "    noisy, clean = noisy.to(device), clean.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(noisy)[\"final\"]\n",
    "\n",
    "    # Move tensors to CPU\n",
    "    noisy = noisy.cpu()\n",
    "    outputs = outputs.cpu()\n",
    "    clean = clean.cpu()\n",
    "\n",
    "    # Cap num_samples if batch smaller\n",
    "    num_samples = min(num_samples, noisy.shape[0])\n",
    "\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
    "\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, 3)  # Handle single row\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        axes[i, 0].imshow(noisy[i].squeeze(0), cmap=\"gray\")\n",
    "        axes[i, 0].set_title(\"Noisy Image\")\n",
    "        axes[i, 0].axis(\"off\")\n",
    "\n",
    "        axes[i, 1].imshow(outputs[i].squeeze(0), cmap=\"gray\")\n",
    "        axes[i, 1].set_title(\"Denoised Image\")\n",
    "        axes[i, 1].axis(\"off\")\n",
    "\n",
    "        axes[i, 2].imshow(clean[i].squeeze(0), cmap=\"gray\")\n",
    "        axes[i, 2].set_title(\"Ground Truth\")\n",
    "        axes[i, 2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "visualize_results(model, test_loader, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
