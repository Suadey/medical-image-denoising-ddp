{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95651b1e-0644-4884-ad61-0f7efac7393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from os import path\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import wget\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
    "import csv\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "\n",
    "import lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a822bebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6610a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if data path is correct\n",
    "data_path = \"/home/sulaimon/EXPERIMENT/23/images_001\"\n",
    "image_files = glob.glob(os.path.join(data_path, '*.png'))\n",
    "print(f'Found {len(image_files)} Images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f16dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee04374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Load Data=====\n",
    "def load_xray_image(data_path):\n",
    "    img = Image.open(data_path).convert('L')  # Ensure grayscale\n",
    "    img = img.resize((256, 256))              # Resize to 256x256\n",
    "    img_array = np.array(img, dtype=np.float32) / 255.0  # Normalize to [0,1]\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add channel dimension: (1, 256, 256)\n",
    "    return img_array\n",
    "\n",
    "# Load all images into a numpy array\n",
    "InputImages = np.array([load_xray_image(f) for f in image_files])\n",
    "print(\"Dataset Shape:\", InputImages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78586946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615a40b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Add Noise=====\n",
    "def add_gaussian_noise(images, mean=0.1, stddev=0.1):\n",
    "    noise = torch.normal( mean, std=stddev, size=images.shape)\n",
    "    noisy_images = images + noise\n",
    "    return torch.clamp(noisy_images, 0., 1.)\n",
    "\n",
    "InputImages = torch.tensor(InputImages, dtype=torch.float32)\n",
    "noisy_images = add_gaussian_noise(InputImages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e0c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f0b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Data Loader=====\n",
    "class X_rayDataset(Dataset):\n",
    "    def __init__(self, noisy, clean):\n",
    "        self.noisy = noisy\n",
    "        self.clean = clean\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.noisy)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.noisy[idx], self.clean[idx]\n",
    "\n",
    "\n",
    "#Splitting and Data Loader Creation\n",
    "dataset = X_rayDataset(noisy_images, InputImages)\n",
    "\n",
    "#Ensuring reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "train_size = int(0.5 * len(dataset))\n",
    "val_size = int(0.33 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=16)\n",
    "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "#Verify the samples\n",
    "def print_dataset_shapes(loader, name):\n",
    "    data_iter = iter(loader)\n",
    "    noisy_sample, clean_sample = next(data_iter)\n",
    "    print(f\"{name} set: Noisy shape: {noisy_sample.shape}, Clean shape: {clean_sample.shape}\")\n",
    "\n",
    "\n",
    "print_dataset_shapes(train_loader, \"Train\")\n",
    "print_dataset_shapes(val_loader, \"Validation\")\n",
    "print_dataset_shapes(test_loader, \"Test\")\n",
    "\n",
    "\n",
    "print(f\"Train set size: {len(train_set)}\")\n",
    "print(f\"Val Set: {len(val_set)}\")\n",
    "print(f\"Test Set: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb88f69-0d3b-4702-9b26-d5721ceb34c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9564a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====UNet Model Definition=====\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_channels=1, Nc=64):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Contracting Path\n",
    "        self.conv1 = self.conv_block(input_channels, Nc)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv2 = self.conv_block(Nc, Nc * 2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv3 = self.conv_block(Nc * 2, Nc * 4)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv4 = self.conv_block(Nc * 4, Nc * 8)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv5 = self.conv_block(Nc * 8, Nc * 16)\n",
    "\n",
    "        # Expanding Path\n",
    "        self.upconv6 = nn.ConvTranspose2d(Nc * 16, Nc * 8, kernel_size=2, stride=2)\n",
    "        self.conv6 = self.conv_block(Nc * 16, Nc * 8)\n",
    "\n",
    "        self.upconv7 = nn.ConvTranspose2d(Nc * 8, Nc * 4, kernel_size=2, stride=2)\n",
    "        self.conv7 = self.conv_block(Nc * 8, Nc * 4)\n",
    "\n",
    "        self.upconv8 = nn.ConvTranspose2d(Nc * 4, Nc * 2, kernel_size=2, stride=2)\n",
    "        self.conv8 = self.conv_block(Nc * 4, Nc * 2)\n",
    "\n",
    "        self.upconv9 = nn.ConvTranspose2d(Nc * 2, Nc, kernel_size=2, stride=2)\n",
    "        self.conv9 = self.conv_block(Nc * 2, Nc)\n",
    "\n",
    "        # Final output for grayscale (only 1 channel)\n",
    "        self.final_conv = nn.Conv2d(Nc, 1, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = {}\n",
    "\n",
    "        # Contracting Path\n",
    "        outputs[\"conv1\"] = self.conv1(x)\n",
    "        pool1 = self.pool1(outputs[\"conv1\"])\n",
    "\n",
    "        outputs[\"conv2\"] = self.conv2(pool1)\n",
    "        pool2 = self.pool2(outputs[\"conv2\"])\n",
    "\n",
    "        outputs[\"conv3\"] = self.conv3(pool2)\n",
    "        pool3 = self.pool3(outputs[\"conv3\"])\n",
    "\n",
    "        outputs[\"conv4\"] = self.conv4(pool3)\n",
    "        pool4 = self.pool4(outputs[\"conv4\"])\n",
    "\n",
    "        outputs[\"conv5\"] = self.conv5(pool4)  # Bottleneck\n",
    "\n",
    "        # Expanding Path\n",
    "        up6 = self.upconv6(outputs[\"conv5\"])\n",
    "        merge6 = torch.cat((outputs[\"conv4\"], up6), dim=1)\n",
    "        outputs[\"conv6\"] = self.conv6(merge6)\n",
    "\n",
    "        up7 = self.upconv7(outputs[\"conv6\"])\n",
    "        merge7 = torch.cat((outputs[\"conv3\"], up7), dim=1)\n",
    "        outputs[\"conv7\"] = self.conv7(merge7)\n",
    "\n",
    "        up8 = self.upconv8(outputs[\"conv7\"])\n",
    "        merge8 = torch.cat((outputs[\"conv2\"], up8), dim=1)\n",
    "        outputs[\"conv8\"] = self.conv8(merge8)\n",
    "\n",
    "        up9 = self.upconv9(outputs[\"conv8\"])\n",
    "        merge9 = torch.cat((outputs[\"conv1\"], up9), dim=1)\n",
    "        outputs[\"conv9\"] = self.conv9(merge9)\n",
    "\n",
    "        outputs[\"final\"] = self.final_conv(outputs[\"conv9\"])\n",
    "\n",
    "        return outputs  # Return all intermediate outputs\n",
    "\n",
    "# Example usage\n",
    "model = UNet(input_channels=1, Nc=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90208285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a1a25c-c571-40ca-b861-78bb74de9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Metrics=====\n",
    "\n",
    "def psnr_metric(y_true, y_pred):\n",
    "    mse = F.mse_loss(y_pred, y_true)\n",
    "    return 10 * torch.log10(1.0 / mse)\n",
    "\n",
    "def ssim_metric(y_true, y_pred):\n",
    "    y_true = y_true.detach().cpu().numpy()\n",
    "    y_pred = y_pred.detach().cpu().numpy()\n",
    "    ssim_scores = []\n",
    "    for i in range(y_true.shape[0]):  # loop over batch\n",
    "        ssim_score = ssim(y_true[i,0], y_pred[i,0], data_range=1.0)  # Only first (and only) channel\n",
    "        ssim_scores.append(ssim_score)\n",
    "    return torch.tensor(ssim_scores).mean()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.L1Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b15db11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Model Training=====\n",
    "def train_model(model, train_loader, val_loader, epochs=50, save_path=\"best_model_unet_10.pth\"):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model.to(device)  # Move model to GPU if available\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.L1Loss()  # Use L1Loss as defined earlier\n",
    "\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for noisy, clean in train_loader:\n",
    "            noisy, clean = noisy.to(device), clean.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(noisy)[\"final\"]\n",
    "            loss = loss_fn(outputs, clean)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for noisy, clean in val_loader:\n",
    "                noisy, clean = noisy.to(device), clean.to(device)\n",
    "\n",
    "                outputs = model(noisy)[\"final\"]\n",
    "                loss = loss_fn(outputs, clean)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} => Train Loss: {avg_train_loss:.6f}, Validation Loss: {avg_val_loss:.6f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Model saved at epoch {epoch+1} with best validation loss: {best_loss:.6f}\")\n",
    "\n",
    "# Example: Call training\n",
    "train_model(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17aaf76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8758b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Model Testing=====\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Initialize LPIPS model globally\n",
    "loss_fn_lpips = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "def test_model(model, test_loader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    total_psnr = 0.0\n",
    "    total_ssim = 0.0\n",
    "    total_lpips = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for noisy, clean in test_loader:\n",
    "            noisy, clean = noisy.to(device), clean.to(device)\n",
    "            outputs = model(noisy)[\"final\"]\n",
    "\n",
    "            for i in range(noisy.shape[0]):\n",
    "                y_true = clean[i, 0].cpu().numpy()\n",
    "                y_pred = outputs[i, 0].cpu().numpy()\n",
    "\n",
    "                # PSNR and SSIM\n",
    "                total_psnr += psnr(y_true, y_pred, data_range=1.0)\n",
    "                total_ssim += ssim(y_true, y_pred, data_range=1.0, win_size=3)\n",
    "\n",
    "                # LPIPS: convert single-channel to 3-channel and normalize to [-1, 1]\n",
    "                out_img = outputs[i].unsqueeze(0)  # [1, 1, H, W]\n",
    "                tgt_img = clean[i].unsqueeze(0)    # [1, 1, H, W]\n",
    "\n",
    "                if out_img.shape[1] == 1:\n",
    "                    out_img = out_img.repeat(1, 3, 1, 1)\n",
    "                    tgt_img = tgt_img.repeat(1, 3, 1, 1)\n",
    "\n",
    "                out_img = (out_img * 2) - 1\n",
    "                tgt_img = (tgt_img * 2) - 1\n",
    "\n",
    "                lpips_score = loss_fn_lpips(out_img.to(device), tgt_img.to(device))\n",
    "                total_lpips += lpips_score.item()\n",
    "\n",
    "                num_samples += 1\n",
    "\n",
    "    avg_psnr = total_psnr / num_samples\n",
    "    avg_ssim = total_ssim / num_samples\n",
    "    avg_lpips = total_lpips / num_samples\n",
    "\n",
    "    print(f\"Average PSNR: {avg_psnr:.2f} dB\")\n",
    "    print(f\"Average SSIM: {avg_ssim:.4f}\")\n",
    "    print(f\"Average LPIPS: {avg_lpips:.4f}\")\n",
    "    print(f\"Test samples evaluated: {num_samples}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load('best_model_unet_10.pth', map_location=device))\n",
    "\n",
    "test_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e2bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171b6f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Save Sample Test Data=====\n",
    "def save_test_image_triplets_from_model(model, test_loader, device=\"cpu\", output_dir=\"saved_unet_images\"):\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get one batch from the test set\n",
    "    noisy_imgs, clean_imgs = next(iter(test_loader))\n",
    "    noisy_imgs = noisy_imgs.to(device)\n",
    "    clean_imgs = clean_imgs.to(device)\n",
    "\n",
    "    # Run inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_imgs = model(noisy_imgs)[\"final\"]  # Assuming model returns dict with key \"final\"\n",
    "\n",
    "    # Move to CPU for saving\n",
    "    noisy_imgs = noisy_imgs.cpu()\n",
    "    output_imgs = output_imgs.cpu()\n",
    "    clean_imgs = clean_imgs.cpu()\n",
    "\n",
    "    # Save the first 10 triplets\n",
    "    for i in range(min(10, len(clean_imgs))):\n",
    "        save_image(noisy_imgs[i], os.path.join(output_dir, f\"img_{i+1:02d}_noisy.png\"))\n",
    "        save_image(output_imgs[i], os.path.join(output_dir, f\"img_{i+1:02d}_denoised.png\"))\n",
    "        save_image(clean_imgs[i], os.path.join(output_dir, f\"img_{i+1:02d}_clean.png\"))\n",
    "\n",
    "    print(f\"Saved {min(10, len(clean_imgs)) * 3} images (triplets) to '{output_dir}'\")\n",
    "\n",
    "\n",
    "save_test_image_triplets_from_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae705270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0845cfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Save Metrics to CSV=====\n",
    "def save_metrics_csv_from_model(model, test_loader, device=\"cpu\", csv_path=\"unet_10.csv\"):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn_lpips = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "    psnr_list = []\n",
    "    ssim_list = []\n",
    "    lpips_list = []\n",
    "    count = 0\n",
    "\n",
    "    with open(csv_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Image Index\", \"PSNR\", \"SSIM\", \"LPIPS\"])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for noisy, clean in test_loader:\n",
    "                noisy = noisy.to(device)\n",
    "                clean = clean.to(device)\n",
    "\n",
    "                outputs = model(noisy)[\"final\"]\n",
    "\n",
    "                clean_np = clean.squeeze(1).cpu().numpy()     # (B, H, W)\n",
    "                outputs_np = outputs.squeeze(1).cpu().numpy() # (B, H, W)\n",
    "\n",
    "                for i in range(clean_np.shape[0]):\n",
    "                    # PSNR & SSIM\n",
    "                    psnr_val = psnr(clean_np[i], outputs_np[i], data_range=1.0)\n",
    "                    ssim_val = ssim(clean_np[i], outputs_np[i], data_range=1.0, win_size=3)\n",
    "\n",
    "                    # LPIPS: prepare 3-channel normalized input\n",
    "                    out_img = outputs[i].unsqueeze(0)  # [1, 1, H, W]\n",
    "                    tgt_img = clean[i].unsqueeze(0)\n",
    "\n",
    "                    if out_img.shape[1] == 1:\n",
    "                        out_img = out_img.repeat(1, 3, 1, 1)\n",
    "                        tgt_img = tgt_img.repeat(1, 3, 1, 1)\n",
    "\n",
    "                    out_img = (out_img * 2) - 1\n",
    "                    tgt_img = (tgt_img * 2) - 1\n",
    "\n",
    "                    lpips_val = loss_fn_lpips(out_img.to(device), tgt_img.to(device)).item()\n",
    "\n",
    "                    psnr_list.append(psnr_val)\n",
    "                    ssim_list.append(ssim_val)\n",
    "                    lpips_list.append(lpips_val)\n",
    "\n",
    "                    writer.writerow([count + 1, psnr_val, ssim_val, lpips_val])\n",
    "                    count += 1\n",
    "\n",
    "        writer.writerow([])  # Blank line\n",
    "        writer.writerow([\"Average\", np.mean(psnr_list), np.mean(ssim_list), np.mean(lpips_list)])\n",
    "\n",
    "    print(f\" Saved PSNR/SSIM/LPIPS metrics for {count} images to '{csv_path}'\")\n",
    "    \n",
    "save_metrics_csv_from_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038df01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772129f3-c8ea-403f-a624-10b38b013b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Visualise Clean, Noisy, and Denoised Image Test sets=====\n",
    "def visualize_results(model, test_loader, device, num_samples=10):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    data_iter = iter(test_loader)\n",
    "    noisy, clean = next(data_iter)\n",
    "    noisy, clean = noisy.to(device), clean.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(noisy)[\"final\"]\n",
    "\n",
    "    # Move tensors to CPU\n",
    "    noisy = noisy.cpu()\n",
    "    outputs = outputs.cpu()\n",
    "    clean = clean.cpu()\n",
    "\n",
    "    # Cap num_samples if batch smaller\n",
    "    num_samples = min(num_samples, noisy.shape[0])\n",
    "\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
    "\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, 3)  # Handle single row\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        axes[i, 0].imshow(noisy[i].squeeze(0), cmap=\"gray\")\n",
    "        axes[i, 0].set_title(\"Noisy Image\")\n",
    "        axes[i, 0].axis(\"off\")\n",
    "\n",
    "        axes[i, 1].imshow(outputs[i].squeeze(0), cmap=\"gray\")\n",
    "        axes[i, 1].set_title(\"Denoised Image\")\n",
    "        axes[i, 1].axis(\"off\")\n",
    "\n",
    "        axes[i, 2].imshow(clean[i].squeeze(0), cmap=\"gray\")\n",
    "        axes[i, 2].set_title(\"Ground Truth\")\n",
    "        axes[i, 2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "visualize_results(model, test_loader, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
