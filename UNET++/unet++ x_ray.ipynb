{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95651b1e-0644-4884-ad61-0f7efac7393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sulaimon/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from os import path\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import wget\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
    "import csv\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "\n",
    "import lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2110f00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0b0929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14999 Images.\n"
     ]
    }
   ],
   "source": [
    "##Check if data path is correct\n",
    "data_path = \"/home/sulaimon/EXPERIMENT/23/images_001\"\n",
    "image_files = glob.glob(os.path.join(data_path, '*.png'))\n",
    "print(f'Found {len(image_files)} Images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b98cc17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b2a048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (14999, 1, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "#=====Load Data=====\n",
    "def load_xray_image(data_path):\n",
    "    img = Image.open(data_path).convert('L')  # Ensure grayscale\n",
    "    img = img.resize((256, 256))              # Resize to 256x256\n",
    "    img_array = np.array(img, dtype=np.float32) / 255.0  # Normalize to [0,1]\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add channel dimension: (1, 256, 256)\n",
    "    return img_array\n",
    "\n",
    "# Load all images into a numpy array\n",
    "InputImages = np.array([load_xray_image(f) for f in image_files])\n",
    "print(\"Dataset Shape:\", InputImages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a24583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e820dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(images, mean=0.1, stddev=0.3):\n",
    "    noise = torch.normal( mean, std=stddev, size=images.shape)\n",
    "    noisy_images = images + noise\n",
    "    return torch.clamp(noisy_images, 0., 1.)\n",
    "\n",
    "InputImages = torch.tensor(InputImages, dtype=torch.float32)\n",
    "noisy_images = add_gaussian_noise(InputImages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ab652d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2c0917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Noisy shape: torch.Size([16, 1, 256, 256]), Clean shape: torch.Size([16, 1, 256, 256])\n",
      "Validation set: Noisy shape: torch.Size([16, 1, 256, 256]), Clean shape: torch.Size([16, 1, 256, 256])\n",
      "Test set: Noisy shape: torch.Size([16, 1, 256, 256]), Clean shape: torch.Size([16, 1, 256, 256])\n",
      "Train set size: 7499\n",
      "Val Set: 4949\n",
      "Test Set: 2551\n"
     ]
    }
   ],
   "source": [
    "class X_rayDataset(Dataset):\n",
    "    def __init__(self, noisy, clean):\n",
    "        self.noisy = noisy\n",
    "        self.clean = clean\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.noisy)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.noisy[idx], self.clean[idx]\n",
    "\n",
    "\n",
    "##Splitting and Data Loader Creation\n",
    "dataset = X_rayDataset(noisy_images, InputImages)\n",
    "\n",
    "#Ensuring reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "train_size = int(0.5 * len(dataset))\n",
    "val_size = int(0.33 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=16)\n",
    "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "##Verify the samples\n",
    "def print_dataset_shapes(loader, name):\n",
    "    data_iter = iter(loader)\n",
    "    noisy_sample, clean_sample = next(data_iter)\n",
    "    print(f\"{name} set: Noisy shape: {noisy_sample.shape}, Clean shape: {clean_sample.shape}\")\n",
    "\n",
    "\n",
    "print_dataset_shapes(train_loader, \"Train\")\n",
    "print_dataset_shapes(val_loader, \"Validation\")\n",
    "print_dataset_shapes(test_loader, \"Test\")\n",
    "\n",
    "\n",
    "print(f\"Train set size: {len(train_set)}\")\n",
    "print(f\"Val Set: {len(val_set)}\")\n",
    "print(f\"Test Set: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae61e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6cc324d-3da2-4be6-9ce5-16f10147ddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ConvBlock building: Two 3x3 convolutions with same padding and ReLU\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class UNetplusplus(nn.Module):\n",
    "    # 5 levels with single final output at x40\n",
    "    def __init__(self, input_channels=1, output_channels=1, base_ch=64):  # <-- CHANGED HERE\n",
    "        super(UNetplusplus, self).__init__()\n",
    "\n",
    "        Nc = [base_ch, base_ch*2, base_ch*4, base_ch*8, base_ch*16]\n",
    "\n",
    "        # Encoder Xi0\n",
    "        self.conv0_0 = ConvBlock(input_channels, Nc[0])  # X0_0\n",
    "        self.conv1_0 = ConvBlock(Nc[0], Nc[1])  # X1_0\n",
    "        self.conv2_0 = ConvBlock(Nc[1], Nc[2])  # X2_0\n",
    "        self.conv3_0 = ConvBlock(Nc[2], Nc[3])  # X3_0\n",
    "        self.conv4_0 = ConvBlock(Nc[3], Nc[4])  # X4_0\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # Decoder Level 1 (Xi1)\n",
    "        self.conv0_1 = ConvBlock(Nc[0] + Nc[1], Nc[0])\n",
    "        self.conv1_1 = ConvBlock(Nc[1] + Nc[2], Nc[1])\n",
    "        self.conv2_1 = ConvBlock(Nc[2] + Nc[3], Nc[2])\n",
    "        self.conv3_1 = ConvBlock(Nc[3] + Nc[4], Nc[3])\n",
    "\n",
    "        # Decoder Level 2 (Xi2)\n",
    "        self.conv0_2 = ConvBlock(Nc[0]*2 + Nc[1], Nc[0])\n",
    "        self.conv1_2 = ConvBlock(Nc[1]*2 + Nc[2], Nc[1])\n",
    "        self.conv2_2 = ConvBlock(Nc[2]*2 + Nc[3], Nc[2])\n",
    "\n",
    "        # Decoder Level 3 (Xi3)\n",
    "        self.conv0_3 = ConvBlock(Nc[0]*3 + Nc[1], Nc[0])\n",
    "        self.conv1_3 = ConvBlock(Nc[1]*3 + Nc[2], Nc[1])\n",
    "\n",
    "        # Decoder Level 4 (Xi4)\n",
    "        self.conv0_4 = ConvBlock(Nc[0]*4 + Nc[1], Nc[0])\n",
    "\n",
    "        # Final Convolutions (only 1 output channel)\n",
    "        self.final_X01 = nn.Conv2d(Nc[0], output_channels, kernel_size=1)\n",
    "        self.final_X02 = nn.Conv2d(Nc[0], output_channels, kernel_size=1)\n",
    "        self.final_X03 = nn.Conv2d(Nc[0], output_channels, kernel_size=1)\n",
    "        self.final_X04 = nn.Conv2d(Nc[0], output_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        X0_0 = self.conv0_0(x)\n",
    "        X1_0 = self.conv1_0(self.pool(X0_0))\n",
    "        X2_0 = self.conv2_0(self.pool(X1_0))\n",
    "        X3_0 = self.conv3_0(self.pool(X2_0))\n",
    "        X4_0 = self.conv4_0(self.pool(X3_0))\n",
    "\n",
    "        # Decoder Level 1\n",
    "        X0_1 = self.conv0_1(torch.cat([X0_0, F.interpolate(X1_0, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "        X1_1 = self.conv1_1(torch.cat([X1_0, F.interpolate(X2_0, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "        X2_1 = self.conv2_1(torch.cat([X2_0, F.interpolate(X3_0, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "        X3_1 = self.conv3_1(torch.cat([X3_0, F.interpolate(X4_0, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "\n",
    "        # Level 2\n",
    "        X0_2 = self.conv0_2(torch.cat([X0_0, X0_1, F.interpolate(X1_1, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "        X1_2 = self.conv1_2(torch.cat([X1_0, X1_1, F.interpolate(X2_1, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "        X2_2 = self.conv2_2(torch.cat([X2_0, X2_1, F.interpolate(X3_1, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "\n",
    "        # Level 3\n",
    "        X0_3 = self.conv0_3(torch.cat([X0_0, X0_1, X0_2, F.interpolate(X1_2, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "        X1_3 = self.conv1_3(torch.cat([X1_0, X1_1, X1_2, F.interpolate(X2_2, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "\n",
    "        # Level 4\n",
    "        X0_4 = self.conv0_4(torch.cat([X0_0, X0_1, X0_2, X0_3, F.interpolate(X1_3, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "\n",
    "        output = self.final_X04(X0_4)\n",
    "\n",
    "        return {\"final\": output, \"X01\": self.final_X01(X0_1), \"X02\": self.final_X02(X0_2), \"X03\": self.final_X03(X0_3), \"X04\": output}\n",
    "model = UNetplusplus(input_channels=1, output_channels=1, base_ch=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff23727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Metrics=====\n",
    "def psnr_metric(y_true, y_pred):\n",
    "    mse = F.mse_loss(y_pred, y_true)\n",
    "    return 10 * torch.log10(1.0 / mse)\n",
    "\n",
    "def ssim_metric(y_true, y_pred):\n",
    "    y_true = y_true.detach().cpu().numpy()\n",
    "    y_pred = y_pred.detach().cpu().numpy()\n",
    "    ssim_scores = []\n",
    "    for i in range(y_true.shape[0]):  # loop over batch\n",
    "        ssim_score = ssim(y_true[i,0], y_pred[i,0], data_range=1.0)  # Only first (and only) channel\n",
    "        ssim_scores.append(ssim_score)\n",
    "    return torch.tensor(ssim_scores).mean()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.L1Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e712cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f897d276-db27-4e79-b118-e116b55da125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/50 => Train Loss: 0.057020, Validation Loss: 0.037115\n",
      "Model saved at epoch 1 with best validation loss: 0.037115\n",
      "Epoch 2/50 => Train Loss: 0.039908, Validation Loss: 0.032101\n",
      "Model saved at epoch 2 with best validation loss: 0.032101\n",
      "Epoch 3/50 => Train Loss: 0.034922, Validation Loss: 0.037161\n",
      "Epoch 4/50 => Train Loss: 0.032814, Validation Loss: 0.027636\n",
      "Model saved at epoch 4 with best validation loss: 0.027636\n",
      "Epoch 5/50 => Train Loss: 0.030867, Validation Loss: 0.028103\n",
      "Epoch 6/50 => Train Loss: 0.029556, Validation Loss: 0.038218\n",
      "Epoch 7/50 => Train Loss: 0.028905, Validation Loss: 0.026093\n",
      "Model saved at epoch 7 with best validation loss: 0.026093\n",
      "Epoch 8/50 => Train Loss: 0.028345, Validation Loss: 0.032760\n",
      "Epoch 9/50 => Train Loss: 0.027150, Validation Loss: 0.035785\n",
      "Epoch 10/50 => Train Loss: 0.027355, Validation Loss: 0.060279\n",
      "Epoch 11/50 => Train Loss: 0.027948, Validation Loss: 0.026819\n",
      "Epoch 12/50 => Train Loss: 0.026323, Validation Loss: 0.024469\n",
      "Model saved at epoch 12 with best validation loss: 0.024469\n",
      "Epoch 13/50 => Train Loss: 0.026693, Validation Loss: 0.024467\n",
      "Model saved at epoch 13 with best validation loss: 0.024467\n",
      "Epoch 14/50 => Train Loss: 0.026453, Validation Loss: 0.030472\n",
      "Epoch 15/50 => Train Loss: 0.024954, Validation Loss: 0.028002\n",
      "Epoch 16/50 => Train Loss: 0.024711, Validation Loss: 0.025926\n",
      "Epoch 17/50 => Train Loss: 0.023855, Validation Loss: 0.025394\n",
      "Epoch 18/50 => Train Loss: 0.023351, Validation Loss: 0.025811\n",
      "Epoch 19/50 => Train Loss: 0.024397, Validation Loss: 0.031239\n",
      "Epoch 20/50 => Train Loss: 0.027259, Validation Loss: 0.025531\n",
      "Epoch 21/50 => Train Loss: 0.024438, Validation Loss: 0.023319\n",
      "Model saved at epoch 21 with best validation loss: 0.023319\n",
      "Epoch 22/50 => Train Loss: 0.023083, Validation Loss: 0.025817\n",
      "Epoch 23/50 => Train Loss: 0.022623, Validation Loss: 0.021639\n",
      "Model saved at epoch 23 with best validation loss: 0.021639\n",
      "Epoch 24/50 => Train Loss: 0.022762, Validation Loss: 0.021488\n",
      "Model saved at epoch 24 with best validation loss: 0.021488\n",
      "Epoch 25/50 => Train Loss: 0.022209, Validation Loss: 0.022007\n",
      "Epoch 26/50 => Train Loss: 0.021564, Validation Loss: 0.020847\n",
      "Model saved at epoch 26 with best validation loss: 0.020847\n",
      "Epoch 27/50 => Train Loss: 0.021957, Validation Loss: 0.020997\n",
      "Epoch 28/50 => Train Loss: 0.021155, Validation Loss: 0.025782\n",
      "Epoch 29/50 => Train Loss: 0.021289, Validation Loss: 0.028385\n",
      "Epoch 30/50 => Train Loss: 0.020969, Validation Loss: 0.025024\n",
      "Epoch 31/50 => Train Loss: 0.020786, Validation Loss: 0.020258\n",
      "Model saved at epoch 31 with best validation loss: 0.020258\n",
      "Epoch 32/50 => Train Loss: 0.020843, Validation Loss: 0.020148\n",
      "Model saved at epoch 32 with best validation loss: 0.020148\n",
      "Epoch 33/50 => Train Loss: 0.020332, Validation Loss: 0.025016\n",
      "Epoch 34/50 => Train Loss: 0.020513, Validation Loss: 0.020413\n",
      "Epoch 35/50 => Train Loss: 0.020163, Validation Loss: 0.022230\n",
      "Epoch 36/50 => Train Loss: 0.019968, Validation Loss: 0.020878\n",
      "Epoch 37/50 => Train Loss: 0.019927, Validation Loss: 0.020858\n",
      "Epoch 38/50 => Train Loss: 0.019754, Validation Loss: 0.021908\n",
      "Epoch 39/50 => Train Loss: 0.019375, Validation Loss: 0.022987\n",
      "Epoch 40/50 => Train Loss: 0.019701, Validation Loss: 0.021594\n",
      "Epoch 41/50 => Train Loss: 0.019361, Validation Loss: 0.023658\n",
      "Epoch 42/50 => Train Loss: 0.019145, Validation Loss: 0.020077\n",
      "Model saved at epoch 42 with best validation loss: 0.020077\n",
      "Epoch 43/50 => Train Loss: 0.018820, Validation Loss: 0.020291\n",
      "Epoch 44/50 => Train Loss: 0.018880, Validation Loss: 0.021949\n",
      "Epoch 45/50 => Train Loss: 0.018880, Validation Loss: 0.020331\n",
      "Epoch 46/50 => Train Loss: 0.018400, Validation Loss: 0.021883\n",
      "Epoch 47/50 => Train Loss: 0.018305, Validation Loss: 0.020975\n",
      "Epoch 48/50 => Train Loss: 0.017928, Validation Loss: 0.022432\n",
      "Epoch 49/50 => Train Loss: 0.017851, Validation Loss: 0.022012\n",
      "Epoch 50/50 => Train Loss: 0.017857, Validation Loss: 0.021829\n"
     ]
    }
   ],
   "source": [
    "#=====Training=====\n",
    "def train_model(model, train_loader, val_loader, epochs=50, save_path=\"best_model_unet++_30.pth\"):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model.to(device)  # Move model to GPU if available\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.L1Loss()  # Use L1Loss as defined earlier\n",
    "\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for noisy, clean in train_loader:\n",
    "            noisy, clean = noisy.to(device), clean.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(noisy)[\"final\"]\n",
    "            loss = loss_fn(outputs, clean)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for noisy, clean in val_loader:\n",
    "                noisy, clean = noisy.to(device), clean.to(device)\n",
    "\n",
    "                outputs = model(noisy)[\"final\"]\n",
    "                loss = loss_fn(outputs, clean)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} => Train Loss: {avg_train_loss:.6f}, Validation Loss: {avg_val_loss:.6f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Model saved at epoch {epoch+1} with best validation loss: {best_loss:.6f}\")\n",
    "\n",
    "# Example: Call training\n",
    "train_model(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9390ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LPIPS model globally\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loss_fn_lpips = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "#=====Model Testing=====\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    total_psnr = 0.0\n",
    "    total_ssim = 0.0\n",
    "    total_lpips = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for noisy, clean in test_loader:\n",
    "            noisy, clean = noisy.to(device), clean.to(device)\n",
    "            outputs = model(noisy)[\"final\"]\n",
    "\n",
    "            for i in range(noisy.shape[0]):\n",
    "                y_true = clean[i, 0].cpu().numpy()\n",
    "                y_pred = outputs[i, 0].cpu().numpy()\n",
    "\n",
    "                # PSNR and SSIM\n",
    "                total_psnr += psnr(y_true, y_pred, data_range=1.0)\n",
    "                total_ssim += ssim(y_true, y_pred, data_range=1.0, win_size=3)\n",
    "\n",
    "                # LPIPS: convert single-channel to 3-channel and normalize to [-1, 1]\n",
    "                out_img = outputs[i].unsqueeze(0)  # [1, 1, H, W]\n",
    "                tgt_img = clean[i].unsqueeze(0)    # [1, 1, H, W]\n",
    "\n",
    "                if out_img.shape[1] == 1:\n",
    "                    out_img = out_img.repeat(1, 3, 1, 1)\n",
    "                    tgt_img = tgt_img.repeat(1, 3, 1, 1)\n",
    "\n",
    "                out_img = (out_img * 2) - 1\n",
    "                tgt_img = (tgt_img * 2) - 1\n",
    "\n",
    "                lpips_score = loss_fn_lpips(out_img.to(device), tgt_img.to(device))\n",
    "                total_lpips += lpips_score.item()\n",
    "\n",
    "                num_samples += 1\n",
    "\n",
    "    avg_psnr = total_psnr / num_samples\n",
    "    avg_ssim = total_ssim / num_samples\n",
    "    avg_lpips = total_lpips / num_samples\n",
    "\n",
    "    print(f\"Average PSNR: {avg_psnr:.2f} dB\")\n",
    "    print(f\"Average SSIM: {avg_ssim:.4f}\")\n",
    "    print(f\"Average LPIPS: {avg_lpips:.4f}\")\n",
    "    print(f\"Test samples evaluated: {num_samples}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load('best_model_unet++_30.pth', map_location=device))\n",
    "\n",
    "test_model(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c60fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/sulaimon/.local/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      " Saved PSNR/SSIM/LPIPS metrics for 2551 images to 'unet++_30.csv'\n"
     ]
    }
   ],
   "source": [
    "#=====Save Metrics=====\n",
    "def save_metrics_csv_from_model(model, test_loader, device=\"cpu\", csv_path=\"unet++_30.csv\"):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn_lpips = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "    psnr_list = []\n",
    "    ssim_list = []\n",
    "    lpips_list = []\n",
    "    count = 0\n",
    "\n",
    "    with open(csv_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Image Index\", \"PSNR\", \"SSIM\", \"LPIPS\"])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for noisy, clean in test_loader:\n",
    "                noisy = noisy.to(device)\n",
    "                clean = clean.to(device)\n",
    "\n",
    "                outputs = model(noisy)[\"final\"]\n",
    "\n",
    "                clean_np = clean.squeeze(1).cpu().numpy()     # (B, H, W)\n",
    "                outputs_np = outputs.squeeze(1).cpu().numpy() # (B, H, W)\n",
    "\n",
    "                for i in range(clean_np.shape[0]):\n",
    "                    # PSNR & SSIM\n",
    "                    psnr_val = psnr(clean_np[i], outputs_np[i], data_range=1.0)\n",
    "                    ssim_val = ssim(clean_np[i], outputs_np[i], data_range=1.0, win_size=3)\n",
    "\n",
    "                    # LPIPS: prepare 3-channel normalized input\n",
    "                    out_img = outputs[i].unsqueeze(0)  # [1, 1, H, W]\n",
    "                    tgt_img = clean[i].unsqueeze(0)\n",
    "\n",
    "                    if out_img.shape[1] == 1:\n",
    "                        out_img = out_img.repeat(1, 3, 1, 1)\n",
    "                        tgt_img = tgt_img.repeat(1, 3, 1, 1)\n",
    "\n",
    "                    out_img = (out_img * 2) - 1\n",
    "                    tgt_img = (tgt_img * 2) - 1\n",
    "\n",
    "                    lpips_val = loss_fn_lpips(out_img.to(device), tgt_img.to(device)).item()\n",
    "\n",
    "                    psnr_list.append(psnr_val)\n",
    "                    ssim_list.append(ssim_val)\n",
    "                    lpips_list.append(lpips_val)\n",
    "\n",
    "                    writer.writerow([count + 1, psnr_val, ssim_val, lpips_val])\n",
    "                    count += 1\n",
    "\n",
    "        writer.writerow([])  # Blank line\n",
    "        writer.writerow([\"Average\", np.mean(psnr_list), np.mean(ssim_list), np.mean(lpips_list)])\n",
    "\n",
    "    print(f\" Saved PSNR/SSIM/LPIPS metrics for {count} images to '{csv_path}'\")\n",
    "    \n",
    "save_metrics_csv_from_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23459c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab535727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Save Sample Test Images=====\n",
    "def save_test_image_triplets_from_model(model, test_loader, device=\"cpu\", output_dir=\"saved_unet++_images\"):\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get one batch from the test set\n",
    "    noisy_imgs, clean_imgs = next(iter(test_loader))\n",
    "    noisy_imgs = noisy_imgs.to(device)\n",
    "    clean_imgs = clean_imgs.to(device)\n",
    "\n",
    "    # Run inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_imgs = model(noisy_imgs)[\"final\"]  # Assuming model returns dict with key \"final\"\n",
    "\n",
    "    # Move to CPU for saving\n",
    "    noisy_imgs = noisy_imgs.cpu()\n",
    "    output_imgs = output_imgs.cpu()\n",
    "    clean_imgs = clean_imgs.cpu()\n",
    "\n",
    "    # Save the first 10 triplets\n",
    "    for i in range(min(10, len(clean_imgs))):\n",
    "        save_image(noisy_imgs[i], os.path.join(output_dir, f\"img_{i+1:02d}_noisy.png\"))\n",
    "        save_image(output_imgs[i], os.path.join(output_dir, f\"img_{i+1:02d}_denoised.png\"))\n",
    "        save_image(clean_imgs[i], os.path.join(output_dir, f\"img_{i+1:02d}_clean.png\"))\n",
    "\n",
    "    print(f\"Saved {min(10, len(clean_imgs)) * 3} images (triplets) to '{output_dir}'\")\n",
    "\n",
    "save_test_image_triplets_from_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa09e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Visualise Clean, Noisy, and Denoised Image Test sets=====\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "def visualize_results(model, test_loader, device, num_samples=10):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    data_iter = iter(test_loader)\n",
    "    noisy, clean = next(data_iter)\n",
    "    noisy, clean = noisy.to(device), clean.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(noisy)[\"final\"]\n",
    "\n",
    "    # Move tensors to CPU\n",
    "    noisy = noisy.cpu()\n",
    "    outputs = outputs.cpu()\n",
    "    clean = clean.cpu()\n",
    "\n",
    "    # Cap num_samples if batch smaller\n",
    "    num_samples = min(num_samples, noisy.shape[0])\n",
    "\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
    "\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, 3)  # Handle single row\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        axes[i, 0].imshow(noisy[i].squeeze(0), cmap=\"gray\")\n",
    "        axes[i, 0].set_title(\"Noisy Image\")\n",
    "        axes[i, 0].axis(\"off\")\n",
    "\n",
    "        axes[i, 1].imshow(outputs[i].squeeze(0), cmap=\"gray\")\n",
    "        axes[i, 1].set_title(\"Denoised Image\")\n",
    "        axes[i, 1].axis(\"off\")\n",
    "\n",
    "        axes[i, 2].imshow(clean[i].squeeze(0), cmap=\"gray\")\n",
    "        axes[i, 2].set_title(\"Ground Truth\")\n",
    "        axes[i, 2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "visualize_results(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
