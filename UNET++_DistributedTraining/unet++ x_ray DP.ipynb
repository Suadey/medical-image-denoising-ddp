{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95651b1e-0644-4884-ad61-0f7efac7393d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sulaimon/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from os import path\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import wget\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
    "import csv\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import csv\n",
    "\n",
    "import lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c0b0929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14999 Images.\n"
     ]
    }
   ],
   "source": [
    "##Check if data path is correct\n",
    "data_path = \"/home/sulaimon/EXPERIMENT/23/images_001\"\n",
    "image_files = glob.glob(os.path.join(data_path, '*.png'))\n",
    "print(f'Found {len(image_files)} Images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b2a048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (14999, 1, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "#=====Load Data=====\n",
    "def load_xray_image(data_path):\n",
    "    img = Image.open(data_path).convert('L')  # Ensure grayscale\n",
    "    img = img.resize((256, 256))              # Resize to 256x256\n",
    "    img_array = np.array(img, dtype=np.float32) / 255.0  # Normalize to [0,1]\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add channel dimension: (1, 256, 256)\n",
    "    return img_array\n",
    "\n",
    "# Load all images into a numpy array\n",
    "InputImages = np.array([load_xray_image(f) for f in image_files])\n",
    "print(\"Dataset Shape:\", InputImages.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e820dc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Add Noise=====\n",
    "def add_gaussian_noise(images, mean=0.1, stddev=0.1):\n",
    "    noise = torch.normal( mean, std=stddev, size=images.shape)\n",
    "    noisy_images = images + noise\n",
    "    return torch.clamp(noisy_images, 0., 1.)\n",
    "\n",
    "InputImages = torch.tensor(InputImages, dtype=torch.float32)\n",
    "noisy_images = add_gaussian_noise(InputImages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c0917b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Noisy shape: torch.Size([32, 1, 256, 256]), Clean shape: torch.Size([32, 1, 256, 256])\n",
      "Validation set: Noisy shape: torch.Size([32, 1, 256, 256]), Clean shape: torch.Size([32, 1, 256, 256])\n",
      "Test set: Noisy shape: torch.Size([32, 1, 256, 256]), Clean shape: torch.Size([32, 1, 256, 256])\n",
      "Train set size: 7499\n",
      "Val Set: 4949\n",
      "Test Set: 2551\n"
     ]
    }
   ],
   "source": [
    "#=====Data Loader=====\n",
    "class X_rayDataset(Dataset):\n",
    "    def __init__(self, noisy, clean):\n",
    "        self.noisy = noisy\n",
    "        self.clean = clean\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.noisy)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.noisy[idx], self.clean[idx]\n",
    "\n",
    "\n",
    "##Splitting and Data Loader Creation\n",
    "dataset = X_rayDataset(noisy_images, InputImages)\n",
    "\n",
    "#Ensuring reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "train_size = int(0.5 * len(dataset))\n",
    "val_size = int(0.33 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=32)\n",
    "test_loader = DataLoader(test_set, batch_size=32,shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "##Verify the samples\n",
    "def print_dataset_shapes(loader, name):\n",
    "    data_iter = iter(loader)\n",
    "    noisy_sample, clean_sample = next(data_iter)\n",
    "    print(f\"{name} set: Noisy shape: {noisy_sample.shape}, Clean shape: {clean_sample.shape}\")\n",
    "\n",
    "\n",
    "print_dataset_shapes(train_loader, \"Train\")\n",
    "print_dataset_shapes(val_loader, \"Validation\")\n",
    "print_dataset_shapes(test_loader, \"Test\")\n",
    "\n",
    "\n",
    "print(f\"Train set size: {len(train_set)}\")\n",
    "print(f\"Val Set: {len(val_set)}\")\n",
    "print(f\"Test Set: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae61e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc324d-3da2-4be6-9ce5-16f10147ddda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs with DataParallel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): UNetplusplus(\n",
       "    (conv0_0): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv1_0): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv2_0): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv3_0): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv4_0): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv0_1): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv1_1): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv2_1): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv3_1): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv0_2): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv1_2): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv2_2): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv0_3): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv1_3): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(640, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (conv0_4): ConvBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (4): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (final_X01): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (final_X02): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (final_X03): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (final_X04): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#=====UNet++ Model Definition=====\n",
    "\n",
    "#ConvBlock building: Two 3x3 convolutions with same padding and ReLU\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class UNetplusplus(nn.Module):\n",
    "    # 5 levels with single final output at x40\n",
    "    def __init__(self, input_channels=1, output_channels=1, base_ch=64):  # <-- CHANGED HERE\n",
    "        super(UNetplusplus, self).__init__()\n",
    "\n",
    "        Nc = [base_ch, base_ch*2, base_ch*4, base_ch*8, base_ch*16]\n",
    "\n",
    "        # Encoder Xi0\n",
    "        self.conv0_0 = ConvBlock(input_channels, Nc[0])  # X0_0\n",
    "        self.conv1_0 = ConvBlock(Nc[0], Nc[1])  # X1_0\n",
    "        self.conv2_0 = ConvBlock(Nc[1], Nc[2])  # X2_0\n",
    "        self.conv3_0 = ConvBlock(Nc[2], Nc[3])  # X3_0\n",
    "        self.conv4_0 = ConvBlock(Nc[3], Nc[4])  # X4_0\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "        # Decoder Level 1 (Xi1)\n",
    "        self.conv0_1 = ConvBlock(Nc[0] + Nc[1], Nc[0])\n",
    "        self.conv1_1 = ConvBlock(Nc[1] + Nc[2], Nc[1])\n",
    "        self.conv2_1 = ConvBlock(Nc[2] + Nc[3], Nc[2])\n",
    "        self.conv3_1 = ConvBlock(Nc[3] + Nc[4], Nc[3])\n",
    "\n",
    "        # Decoder Level 2 (Xi2)\n",
    "        self.conv0_2 = ConvBlock(Nc[0]*2 + Nc[1], Nc[0])\n",
    "        self.conv1_2 = ConvBlock(Nc[1]*2 + Nc[2], Nc[1])\n",
    "        self.conv2_2 = ConvBlock(Nc[2]*2 + Nc[3], Nc[2])\n",
    "\n",
    "        # Decoder Level 3 (Xi3)\n",
    "        self.conv0_3 = ConvBlock(Nc[0]*3 + Nc[1], Nc[0])\n",
    "        self.conv1_3 = ConvBlock(Nc[1]*3 + Nc[2], Nc[1])\n",
    "\n",
    "        # Decoder Level 4 (Xi4)\n",
    "        self.conv0_4 = ConvBlock(Nc[0]*4 + Nc[1], Nc[0])\n",
    "\n",
    "        # Final Convolutions (only 1 output channel)\n",
    "        self.final_X01 = nn.Conv2d(Nc[0], output_channels, kernel_size=1)\n",
    "        self.final_X02 = nn.Conv2d(Nc[0], output_channels, kernel_size=1)\n",
    "        self.final_X03 = nn.Conv2d(Nc[0], output_channels, kernel_size=1)\n",
    "        self.final_X04 = nn.Conv2d(Nc[0], output_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        X0_0 = self.conv0_0(x)\n",
    "        X1_0 = self.conv1_0(self.pool(X0_0))\n",
    "        X2_0 = self.conv2_0(self.pool(X1_0))\n",
    "        X3_0 = self.conv3_0(self.pool(X2_0))\n",
    "        X4_0 = self.conv4_0(self.pool(X3_0))\n",
    "\n",
    "        # Decoder Level 1\n",
    "        X0_1 = self.conv0_1(torch.cat([X0_0, F.interpolate(X1_0, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "        X1_1 = self.conv1_1(torch.cat([X1_0, F.interpolate(X2_0, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "        X2_1 = self.conv2_1(torch.cat([X2_0, F.interpolate(X3_0, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "        X3_1 = self.conv3_1(torch.cat([X3_0, F.interpolate(X4_0, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "\n",
    "        # Level 2\n",
    "        X0_2 = self.conv0_2(torch.cat([X0_0, X0_1, F.interpolate(X1_1, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "        X1_2 = self.conv1_2(torch.cat([X1_0, X1_1, F.interpolate(X2_1, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "        X2_2 = self.conv2_2(torch.cat([X2_0, X2_1, F.interpolate(X3_1, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "\n",
    "        # Level 3\n",
    "        X0_3 = self.conv0_3(torch.cat([X0_0, X0_1, X0_2, F.interpolate(X1_2, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "        X1_3 = self.conv1_3(torch.cat([X1_0, X1_1, X1_2, F.interpolate(X2_2, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "\n",
    "        # Level 4\n",
    "        X0_4 = self.conv0_4(torch.cat([X0_0, X0_1, X0_2, X0_3, F.interpolate(X1_3, scale_factor=2, mode='bilinear', align_corners=True)], 1))\n",
    "\n",
    "        output = self.final_X04(X0_4)\n",
    "\n",
    "        return {\"final\": output, \"X01\": self.final_X01(X0_1), \"X02\": self.final_X02(X0_2), \"X03\": self.final_X03(X0_3), \"X04\": output}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNetplusplus(input_channels=1, output_channels=1, base_ch=64)\n",
    "# Wrap with DataParallel if more than one GPU\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs with DataParallel\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2039d3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Metrics=====\n",
    "def psnr_metric(y_true, y_pred):\n",
    "    mse = F.mse_loss(y_pred, y_true)\n",
    "    return 10 * torch.log10(1.0 / mse)\n",
    "\n",
    "def ssim_metric(y_true, y_pred):\n",
    "    y_true = y_true.detach().cpu().numpy()\n",
    "    y_pred = y_pred.detach().cpu().numpy()\n",
    "    ssim_scores = []\n",
    "    for i in range(y_true.shape[0]):  # loop over batch\n",
    "        ssim_score = ssim(y_true[i,0], y_pred[i,0], data_range=1.0)  # Only first (and only) channel\n",
    "        ssim_scores.append(ssim_score)\n",
    "    return torch.tensor(ssim_scores).mean()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.L1Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690877e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f897d276-db27-4e79-b118-e116b55da125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/50 => Train Loss: 0.055844, Validation Loss: 0.022192\n",
      "Model saved at epoch 1 with best validation loss: 0.022192\n",
      "Epoch 2/50 => Train Loss: 0.027498, Validation Loss: 0.033289\n",
      "Epoch 3/50 => Train Loss: 0.025709, Validation Loss: 0.018470\n",
      "Model saved at epoch 3 with best validation loss: 0.018470\n",
      "Epoch 4/50 => Train Loss: 0.023079, Validation Loss: 0.027808\n",
      "Epoch 5/50 => Train Loss: 0.023904, Validation Loss: 0.018481\n",
      "Epoch 6/50 => Train Loss: 0.022512, Validation Loss: 0.021907\n",
      "Epoch 7/50 => Train Loss: 0.021316, Validation Loss: 0.023252\n",
      "Epoch 8/50 => Train Loss: 0.022704, Validation Loss: 0.020045\n",
      "Epoch 9/50 => Train Loss: 0.020289, Validation Loss: 0.019766\n",
      "Epoch 10/50 => Train Loss: 0.019892, Validation Loss: 0.020638\n",
      "Epoch 11/50 => Train Loss: 0.019538, Validation Loss: 0.027600\n",
      "Epoch 12/50 => Train Loss: 0.019505, Validation Loss: 0.028199\n",
      "Epoch 13/50 => Train Loss: 0.019699, Validation Loss: 0.019559\n",
      "Epoch 14/50 => Train Loss: 0.019304, Validation Loss: 0.016893\n",
      "Model saved at epoch 14 with best validation loss: 0.016893\n",
      "Epoch 15/50 => Train Loss: 0.017830, Validation Loss: 0.020641\n",
      "Epoch 16/50 => Train Loss: 0.018418, Validation Loss: 0.018071\n",
      "Epoch 17/50 => Train Loss: 0.018412, Validation Loss: 0.017480\n",
      "Epoch 18/50 => Train Loss: 0.018134, Validation Loss: 0.018913\n",
      "Epoch 19/50 => Train Loss: 0.017355, Validation Loss: 0.017826\n",
      "Epoch 20/50 => Train Loss: 0.017649, Validation Loss: 0.018547\n",
      "Epoch 21/50 => Train Loss: 0.017247, Validation Loss: 0.018152\n",
      "Epoch 22/50 => Train Loss: 0.017431, Validation Loss: 0.016630\n",
      "Model saved at epoch 22 with best validation loss: 0.016630\n",
      "Epoch 23/50 => Train Loss: 0.017108, Validation Loss: 0.016677\n",
      "Epoch 24/50 => Train Loss: 0.017072, Validation Loss: 0.017242\n",
      "Epoch 25/50 => Train Loss: 0.016692, Validation Loss: 0.017862\n",
      "Epoch 26/50 => Train Loss: 0.016840, Validation Loss: 0.017046\n",
      "Epoch 27/50 => Train Loss: 0.016496, Validation Loss: 0.016197\n",
      "Model saved at epoch 27 with best validation loss: 0.016197\n",
      "Epoch 28/50 => Train Loss: 0.016162, Validation Loss: 0.016741\n",
      "Epoch 29/50 => Train Loss: 0.016949, Validation Loss: 2.040888\n",
      "Epoch 30/50 => Train Loss: 0.018033, Validation Loss: 0.016327\n",
      "Epoch 31/50 => Train Loss: 0.016236, Validation Loss: 0.015882\n",
      "Model saved at epoch 31 with best validation loss: 0.015882\n",
      "Epoch 32/50 => Train Loss: 0.015929, Validation Loss: 0.033168\n",
      "Epoch 33/50 => Train Loss: 0.016451, Validation Loss: 0.015213\n",
      "Model saved at epoch 33 with best validation loss: 0.015213\n",
      "Epoch 34/50 => Train Loss: 0.015596, Validation Loss: 0.023326\n",
      "Epoch 35/50 => Train Loss: 0.015693, Validation Loss: 0.014743\n",
      "Model saved at epoch 35 with best validation loss: 0.014743\n",
      "Epoch 36/50 => Train Loss: 0.015740, Validation Loss: 0.031310\n",
      "Epoch 37/50 => Train Loss: 0.016696, Validation Loss: 0.015161\n",
      "Epoch 38/50 => Train Loss: 0.016126, Validation Loss: 0.015401\n",
      "Epoch 39/50 => Train Loss: 0.015704, Validation Loss: 0.015142\n",
      "Epoch 40/50 => Train Loss: 0.015322, Validation Loss: 0.014915\n",
      "Epoch 41/50 => Train Loss: 0.014973, Validation Loss: 0.014543\n",
      "Model saved at epoch 41 with best validation loss: 0.014543\n",
      "Epoch 42/50 => Train Loss: 0.015650, Validation Loss: 0.015805\n",
      "Epoch 43/50 => Train Loss: 0.014837, Validation Loss: 0.014554\n",
      "Epoch 44/50 => Train Loss: 0.016331, Validation Loss: 0.015990\n",
      "Epoch 45/50 => Train Loss: 0.015279, Validation Loss: 0.014512\n",
      "Model saved at epoch 45 with best validation loss: 0.014512\n",
      "Epoch 46/50 => Train Loss: 0.016147, Validation Loss: 0.016692\n",
      "Epoch 47/50 => Train Loss: 0.015114, Validation Loss: 0.014907\n",
      "Epoch 48/50 => Train Loss: 0.014759, Validation Loss: 0.014838\n",
      "Epoch 49/50 => Train Loss: 0.014691, Validation Loss: 0.016674\n",
      "Epoch 50/50 => Train Loss: 0.014735, Validation Loss: 0.014292\n",
      "Model saved at epoch 50 with best validation loss: 0.014292\n"
     ]
    }
   ],
   "source": [
    "#=====Model Training=====\n",
    "def train_model(model, train_loader, val_loader, epochs=50, save_path=\"best_model_unetpp_DP_10.pth\"):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model.to(device)  # Move model to GPU if available\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.L1Loss()  # Use L1Loss as defined earlier\n",
    "\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for noisy, clean in train_loader:\n",
    "            noisy, clean = noisy.to(device), clean.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(noisy)[\"final\"]\n",
    "            loss = loss_fn(outputs, clean)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        val_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for noisy, clean in val_loader:\n",
    "                noisy, clean = noisy.to(device), clean.to(device)\n",
    "\n",
    "                outputs = model(noisy)[\"final\"]\n",
    "                loss = loss_fn(outputs, clean)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} => Train Loss: {avg_train_loss:.6f}, Validation Loss: {avg_val_loss:.6f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Model saved at epoch {epoch+1} with best validation loss: {best_loss:.6f}\")\n",
    "\n",
    "# Example: Call training\n",
    "train_model(model, train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb32b32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b5f916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/sulaimon/.local/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      "Average PSNR: 34.09 dB\n",
      "Average SSIM: 0.9084\n",
      "Average LPIPS: 0.1565\n",
      "Test samples evaluated: 2551\n"
     ]
    }
   ],
   "source": [
    "# Initialize LPIPS model globally \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loss_fn_lpips = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "#=====Testing=====\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    total_psnr = 0.0\n",
    "    total_ssim = 0.0\n",
    "    total_lpips = 0.0\n",
    "    num_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for noisy, clean in test_loader:\n",
    "            noisy, clean = noisy.to(device), clean.to(device)\n",
    "            outputs = model(noisy)[\"final\"]\n",
    "\n",
    "            for i in range(noisy.shape[0]):\n",
    "                y_true = clean[i,0].cpu().numpy()   # (H,W) for grayscale\n",
    "                y_pred = outputs[i,0].cpu().numpy() # (H,W) for grayscale\n",
    "\n",
    "                total_psnr += psnr(y_true, y_pred, data_range=1.0)\n",
    "                total_ssim += ssim(y_true, y_pred, data_range=1.0, win_size=3)  # multichannel=False by default\n",
    "\n",
    "                # LPIPS: convert single-channel to 3-channel and normalize to [-1, 1]\n",
    "                out_img = outputs[i].unsqueeze(0)  # [1, 1, H, W]\n",
    "                tgt_img = clean[i].unsqueeze(0)    # [1, 1, H, W]\n",
    "\n",
    "                if out_img.shape[1] == 1:\n",
    "                    out_img = out_img.repeat(1, 3, 1, 1)\n",
    "                    tgt_img = tgt_img.repeat(1, 3, 1, 1)\n",
    "\n",
    "                out_img = (out_img * 2) - 1\n",
    "                tgt_img = (tgt_img * 2) - 1\n",
    "\n",
    "                lpips_score = loss_fn_lpips(out_img.to(device), tgt_img.to(device))\n",
    "                total_lpips += lpips_score.item()\n",
    "\n",
    "                num_samples += 1\n",
    "\n",
    "    avg_psnr = total_psnr / num_samples\n",
    "    avg_ssim = total_ssim / num_samples\n",
    "    avg_lpips = total_lpips / num_samples\n",
    "\n",
    "    print(f\"Average PSNR: {avg_psnr:.2f} dB\")\n",
    "    print(f\"Average SSIM: {avg_ssim:.4f}\")\n",
    "    print(f\"Average LPIPS: {avg_lpips:.4f}\")\n",
    "    print(f\"Test samples evaluated: {num_samples}\")\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('best_model_unetpp_DP_10.pth', map_location=device))\n",
    "\n",
    "test_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23459c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab535727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Save Sample data (Clean, Noisy, Denoised)=====\n",
    "def save_test_image_triplets_from_model(model, test_loader, device=\"cpu\", output_dir=\"saved_unet++DT_images\"):\n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get one batch from the test set\n",
    "    noisy_imgs, clean_imgs = next(iter(test_loader))\n",
    "    noisy_imgs = noisy_imgs.to(device)\n",
    "    clean_imgs = clean_imgs.to(device)\n",
    "\n",
    "    # Run inference\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_imgs = model(noisy_imgs)[\"final\"]  # Assuming model returns dict with key \"final\"\n",
    "\n",
    "    # Move to CPU for saving\n",
    "    noisy_imgs = noisy_imgs.cpu()\n",
    "    output_imgs = output_imgs.cpu()\n",
    "    clean_imgs = clean_imgs.cpu()\n",
    "\n",
    "    # Save the first 10 triplets\n",
    "    for i in range(min(10, len(clean_imgs))):\n",
    "        save_image(noisy_imgs[i], os.path.join(output_dir, f\"img_{i+1:02d}_noisy.png\"))\n",
    "        save_image(output_imgs[i], os.path.join(output_dir, f\"img_{i+1:02d}_denoised.png\"))\n",
    "        save_image(clean_imgs[i], os.path.join(output_dir, f\"img_{i+1:02d}_clean.png\"))\n",
    "\n",
    "    print(f\"Saved {min(10, len(clean_imgs)) * 3} images (triplets) to '{output_dir}'\")\n",
    "\n",
    "\n",
    "save_test_image_triplets_from_model(model, test_loader, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aa058f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa09e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /home/sulaimon/.local/lib/python3.10/site-packages/lpips/weights/v0.1/alex.pth\n",
      " Saved PSNR/SSIM/LPIPS metrics for 2551 images to 'unetpp_DP_10.csv'\n"
     ]
    }
   ],
   "source": [
    "#=====Save Metrics to CSV=====\n",
    "def save_metrics_csv_from_model(model, test_loader, device=\"cpu\", csv_path=\"unetpp_DP_10.csv\"):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    loss_fn_lpips = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "    psnr_list = []\n",
    "    ssim_list = []\n",
    "    lpips_list = []\n",
    "    count = 0\n",
    "\n",
    "    with open(csv_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Image Index\", \"PSNR\", \"SSIM\", \"LPIPS\"])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for noisy, clean in test_loader:\n",
    "                noisy = noisy.to(device)\n",
    "                clean = clean.to(device)\n",
    "\n",
    "                outputs = model(noisy)[\"final\"]\n",
    "\n",
    "                clean_np = clean.squeeze(1).cpu().numpy()     # (B, H, W)\n",
    "                outputs_np = outputs.squeeze(1).cpu().numpy() # (B, H, W)\n",
    "\n",
    "                for i in range(clean_np.shape[0]):\n",
    "                    # PSNR & SSIM\n",
    "                    psnr_val = psnr(clean_np[i], outputs_np[i], data_range=1.0)\n",
    "                    ssim_val = ssim(clean_np[i], outputs_np[i], data_range=1.0, win_size=3)\n",
    "\n",
    "                    # LPIPS: prepare 3-channel normalized input\n",
    "                    out_img = outputs[i].unsqueeze(0)  # [1, 1, H, W]\n",
    "                    tgt_img = clean[i].unsqueeze(0)\n",
    "\n",
    "                    if out_img.shape[1] == 1:\n",
    "                        out_img = out_img.repeat(1, 3, 1, 1)\n",
    "                        tgt_img = tgt_img.repeat(1, 3, 1, 1)\n",
    "\n",
    "                    out_img = (out_img * 2) - 1\n",
    "                    tgt_img = (tgt_img * 2) - 1\n",
    "\n",
    "                    lpips_val = loss_fn_lpips(out_img.to(device), tgt_img.to(device)).item()\n",
    "\n",
    "                    psnr_list.append(psnr_val)\n",
    "                    ssim_list.append(ssim_val)\n",
    "                    lpips_list.append(lpips_val)\n",
    "\n",
    "                    writer.writerow([count + 1, psnr_val, ssim_val, lpips_val])\n",
    "                    count += 1\n",
    "\n",
    "        writer.writerow([])  # Blank line\n",
    "        writer.writerow([\"Average\", np.mean(psnr_list), np.mean(ssim_list), np.mean(lpips_list)])\n",
    "\n",
    "    print(f\" Saved PSNR/SSIM/LPIPS metrics for {count} images to '{csv_path}'\")\n",
    "    \n",
    "save_metrics_csv_from_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=====Visualise Clean, Noisy, and Denoised Image Test sets=====\n",
    "def visualize_results(model, test_loader, device, num_samples=10):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    data_iter = iter(test_loader)\n",
    "    noisy, clean = next(data_iter)\n",
    "    noisy, clean = noisy.to(device), clean.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(noisy)[\"final\"]\n",
    "\n",
    "    # Move tensors to CPU\n",
    "    noisy = noisy.cpu()\n",
    "    outputs = outputs.cpu()\n",
    "    clean = clean.cpu()\n",
    "\n",
    "    # Cap num_samples if batch smaller\n",
    "    num_samples = min(num_samples, noisy.shape[0])\n",
    "\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(12, 4 * num_samples))\n",
    "\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, 3)  # Handle single row\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        axes[i, 0].imshow(noisy[i].squeeze(0), cmap=\"gray\")\n",
    "        axes[i, 0].set_title(\"Noisy Image\")\n",
    "        axes[i, 0].axis(\"off\")\n",
    "\n",
    "        axes[i, 1].imshow(outputs[i].squeeze(0), cmap=\"gray\")\n",
    "        axes[i, 1].set_title(\"Denoised Image\")\n",
    "        axes[i, 1].axis(\"off\")\n",
    "\n",
    "        axes[i, 2].imshow(clean[i].squeeze(0), cmap=\"gray\")\n",
    "        axes[i, 2].set_title(\"Ground Truth\")\n",
    "        axes[i, 2].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "visualize_results(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a469b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
